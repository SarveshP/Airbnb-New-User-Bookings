{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime, date\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# sessions\n",
    "df_sessions = pd.read_csv(\"Data/sessions.csv\")\n",
    "df_sessions['id'] = df_sessions['user_id']\n",
    "df_sessions = df_sessions.drop(['user_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Session data...\n"
     ]
    }
   ],
   "source": [
    "# Preparing Session data\n",
    "print('Working on Session data...')\n",
    "# Filling with NaN for missing values\n",
    "df_sessions.action = df_sessions.action.fillna('NAN')\n",
    "df_sessions.action_type = df_sessions.action_type.fillna('NAN')\n",
    "df_sessions.action_detail = df_sessions.action_detail.fillna('NAN')\n",
    "df_sessions.device_type = df_sessions.device_type.fillna('NAN')\n",
    "\n",
    "# Action values with low frequency are changed to 'OTHER'\n",
    "act_freq = 100  #Threshold for frequency\n",
    "act = dict(zip(*np.unique(df_sessions.action, return_counts=True)))\n",
    "df_sessions.action = df_sessions.action.apply(lambda x: 'OTHER' if act[x] < act_freq else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Computing value_counts. These are going to be used in the one-hot encoding\n",
    "f_act = df_sessions.action.value_counts().argsort()\n",
    "f_act_detail = df_sessions.action_detail.value_counts().argsort()\n",
    "f_act_type = df_sessions.action_type.value_counts().argsort()\n",
    "f_dev_type = df_sessions.device_type.value_counts().argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "view_search_results               155\n",
       "p3                                152\n",
       "NAN                               154\n",
       "-unknown-                         153\n",
       "wishlist_content_update           151\n",
       "user_profile                      149\n",
       "change_trip_characteristics       150\n",
       "similar_listings                  148\n",
       "user_social_connections           147\n",
       "update_listing                    146\n",
       "listing_reviews                   145\n",
       "dashboard                         144\n",
       "user_wishlists                    143\n",
       "header_userpic                    142\n",
       "message_thread                    141\n",
       "edit_profile                      140\n",
       "message_post                      139\n",
       "contact_host                      138\n",
       "unavailable_dates                 137\n",
       "confirm_email_link                136\n",
       "create_user                       135\n",
       "change_contact_host_dates         134\n",
       "user_profile_content_update       133\n",
       "user_reviews                      132\n",
       "p5                                131\n",
       "login                             130\n",
       "your_trips                        129\n",
       "p1                                128\n",
       "notifications                     127\n",
       "profile_verifications             126\n",
       "                                 ... \n",
       "share                              29\n",
       "view_security_checks               28\n",
       "remove_dashboard_alert             27\n",
       "delete_listing                     26\n",
       "place_worth                        25\n",
       "create_payment_instrument          24\n",
       "complete_booking                   23\n",
       "view_identity_verifications        22\n",
       "calculate_worth                    21\n",
       "alteration_request                 20\n",
       "change_availability                19\n",
       "view_resolutions                   18\n",
       "view_user_real_names               17\n",
       "phone_numbers                      16\n",
       "create_alteration_request          15\n",
       "set_default_payment_instrument     14\n",
       "view_ghosting_reasons              13\n",
       "view_ghostings                     12\n",
       "homepage                           11\n",
       "respond_to_alteration_request      10\n",
       "deactivate_user_account             9\n",
       "delete_payment_instrument           8\n",
       "delete_listing_description          7\n",
       "booking                             6\n",
       "host_respond                        5\n",
       "special_offer_field                 4\n",
       "host_refund_guest                   3\n",
       "tos_2014                            2\n",
       "host_respond_page                   1\n",
       "host_standard_suspension            0\n",
       "Name: action_detail, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f_act_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Grouping session by id. Will compute features from all rows with the same id.\n",
    "gr_sess = df_sessions.groupby(['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Loop on dgr_sess to create all the features.\n",
    "samples = []\n",
    "cont = 0\n",
    "ln = len(gr_sess)\n",
    "for g in gr_sess:\n",
    "    if cont%10000 == 0:\n",
    "        print(\"%s from %s\" %(cont, ln))\n",
    "    gr = g[1]\n",
    "    l = []\n",
    "    \n",
    "    # Id\n",
    "    l.append(g[0])\n",
    "    \n",
    "    # first feature - number of values/activity count.\n",
    "    l.append(len(gr))\n",
    "    \n",
    "    sev = gr.secs_elapsed.fillna(0).values\n",
    "    \n",
    "    # action features\n",
    "    # (how many times each value occurs, numb of unique values, mean and std)\n",
    "    c_act = [0] * len(f_act)\n",
    "    for i,v in enumerate(gr.action.values):\n",
    "        c_act[f_act[v]] += 1\n",
    "    _, c_act_uqc = np.unique(gr.action.values, return_counts=True)\n",
    "    c_act += [len(c_act_uqc), np.mean(c_act_uqc), np.std(c_act_uqc)]\n",
    "    l = l + c_act\n",
    "    \n",
    "    # action_detail features\n",
    "    # (how many times each value occurs, numb of unique values, mean and std)\n",
    "    c_act_detail = [0] * len(f_act_detail)\n",
    "    for i,v in enumerate(gr.action_detail.values):\n",
    "        c_act_detail[f_act_detail[v]] += 1 \n",
    "    _, c_act_det_uqc = np.unique(gr.action_detail.values, return_counts=True)\n",
    "    c_act_detail += [len(c_act_det_uqc), np.mean(c_act_det_uqc), np.std(c_act_det_uqc)]\n",
    "    l = l + c_act_detail\n",
    "    \n",
    "    # action_type features\n",
    "    # (how many times each value occurs, numb of unique values, mean and std\n",
    "    # + log of the sum of secs_elapsed for each value)\n",
    "    l_act_type = [0] * len(f_act_type)\n",
    "    c_act_type = [0] * len(f_act_type)\n",
    "    for i,v in enumerate(gr.action_type.values):\n",
    "        l_act_type[f_act_type[v]] += sev[i]   \n",
    "        c_act_type[f_act_type[v]] += 1  \n",
    "    l_act_type = np.log(1 + np.array(l_act_type)).tolist()\n",
    "    _, c_act_type_uqc = np.unique(gr.action_type.values, return_counts=True)\n",
    "    c_act_type += [len(c_act_type_uqc), np.mean(c_act_type_uqc), np.std(c_act_type_uqc)]\n",
    "    l = l + c_act_type + l_act_type    \n",
    "    \n",
    "    # device_type features\n",
    "    # (how many times each value occurs, numb of unique values, mean and std)\n",
    "    c_dev_type  = [0] * len(f_dev_type)\n",
    "    for i,v in enumerate(gr.device_type .values):\n",
    "        c_dev_type[f_dev_type[v]] += 1 \n",
    "    c_dev_type.append(len(np.unique(gr.device_type.values)))\n",
    "    _, c_dev_type_uqc = np.unique(gr.device_type.values, return_counts=True)\n",
    "    c_dev_type += [len(c_dev_type_uqc), np.mean(c_dev_type_uqc), np.std(c_dev_type_uqc)]        \n",
    "    l = l + c_dev_type    \n",
    "    \n",
    "    # Secs_elapsed features        \n",
    "    l_secs = [0] * 5 \n",
    "    l_log = [0] * 15\n",
    "    if len(sev) > 0:\n",
    "        # Simple statistics about the secs_elapsed values.\n",
    "        l_secs[0] = np.log(1 + np.sum(sev))\n",
    "        l_secs[1] = np.log(1 + np.mean(sev)) \n",
    "        l_secs[2] = np.log(1 + np.std(sev))\n",
    "        l_secs[3] = np.log(1 + np.median(sev))\n",
    "        l_secs[4] = l_secs[0] / float(l[1])\n",
    "        \n",
    "        # Values are grouped in 15 intervals. Compute the number of values\n",
    "        # in each interval.\n",
    "        log_sev = np.log(1 + sev).astype(int)\n",
    "        l_log = np.bincount(log_sev, minlength=15).tolist()                      \n",
    "    l = l + l_secs + l_log\n",
    "    \n",
    "    # The list l has the feature values of one sample.\n",
    "    samples.append(l)\n",
    "    cont += 1\n",
    "\n",
    "# Creating a dataframe with the computed features    \n",
    "col_names = []    #name of the columns\n",
    "for i in range(len(samples[0])-1):\n",
    "    col_names.append('c_' + str(i)) \n",
    "# preparing objects    \n",
    "samples = np.array(samples)\n",
    "samp_ar = samples[:, 1:].astype(np.float16)\n",
    "samp_id = samples[:, 0]   #The first element is the id of the sample.\n",
    "\n",
    "# creating the dataframe        \n",
    "df_agg_sess = pd.DataFrame(samp_ar, columns=col_names)\n",
    "df_agg_sess['id'] = samp_id\n",
    "df_agg_sess.index = df_agg_sess.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging train-test with session data\n",
    "# df_all = pd.merge(df_tt, df_agg_sess, how='left')\n",
    "# df_all = df_all.drop(['id'], axis=1)\n",
    "# df_all = df_all.fillna(-2)  #Missing features for samples without sesssion data.\n",
    "# #All types of null \n",
    "# df_all['all_null'] = np.array([sum(r<0) for r in df_all.values])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
